# 【第三周】ResNet+ResNeXt

### 1、**论文阅读与视频学习：**

**ResNet。**阅读论文 _Deep Residual Learning for Image Recognition，CVPR2016_     同时学习下面视频

* [ResNet网络讲解](https://www.bilibili.com/video/BV1T7411T7wa)
* [Pytorch搭建ResNet网络](https://www.bilibili.com/video/BV14E411H7Uw)&#x20;

**ResNeXt。**阅读论文 _Aggregated Residual Transformations for Deep Neural Networks， CVPR 2017_   同时学习下面视频

* [ResNeXt网络讲解](https://www.bilibili.com/video/BV1Ap4y1p71v/)
* [Pytorch搭建ResNeXt网络](https://www.bilibili.com/video/BV1rX4y1N7tE)

### **2、代码作业：**

**AI研习社 “猫狗大战” 比赛（https://god.yanxishe.com/8）**，大家在学习完 LeNet 以后，可以用类似 LetNet 的网络结构参加这个比赛，结果上传以后会有实时得分。 在此基础上，应用 ResNet，看看效果有什么区别。

<figure><img src="https://img-blog.csdnimg.cn/a77cb2afc69541f99a683525ae0d9c34.jpeg" alt=""><figcaption></figcaption></figure>

**本周的思考题：**

1、Residual learning 的基本原理？\
2、Batch Normailization 的原理，思考 BN、LN、IN 的主要区别。\
3、为什么分组卷积可以提升准确率？即然分组卷积可以提升准确率，同时还能降低计算量，分数数量尽量多不行吗？

**附加思考题：**有余力的同学可以学习程明明老师的 Res2Net，体会里面是如何利用分组卷积降低计算量，同时提升网络性能的。感兴趣的同学可以学习一下 Vision Transformer 里的 attention，比较 multi-head 和 分组卷积的区别与联系。
