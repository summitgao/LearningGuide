# LetNet-5和AlexNet

使用CNN解决图像分类问题可以往前追溯到1998年LeCun发表的论文，其中提出了用于解决手写数字识别问题的LeNet。LeNet又名LeNet-5，是因为在LeNet中使用的均是5×5的卷积核。LeNet-5的网络结构如下图所示。

<figure><img src="../.gitbook/assets/image.png" alt=""><figcaption><p>LeNet-5的网络结构</p></figcaption></figure>

LeNet-5中使用的结构直接影响了其后的几乎所有CNN，卷积层 + 降采样层 + 全连接层至今仍然是最主流的结构。卷积操作使网络可以响应和卷积核形状类似的特征，而降采样操作则使网络拥有了一定程度的不变性。

* **第一层：卷积层（C1）：** 这一层的输入就是原始的图像像素：若图像是灰度图(单通道)，LeNet接受的输入层大小为1x32x32，若图像是彩色RGB图(三通道)，LeNet接受的输入层大小为3x32x32；卷积核的尺寸为5x5，个数为6，不使用padding，步长为1；因为没有使用padding，所以这一层的特征图输出尺寸为32-5+1=28，通道数为6，即输出 feature map为 6x28x28；
* \*\*第二层：池化层（S2） ：\*\*输入为一个6x28x28；本层采用的池化窗口大小为2x2，步长为2，所以本层的输出矩阵大小为6x14x14；
* **第三层：卷积层（C3）：** 输入为6x14x14；本层卷积核的尺寸为5x5，个数为16，本层不使用padding，步长为1，所以本层的输出矩阵大小为 16x10x10；
* **第四层：池化层（S4）：** 输入为16x10x10；本层采用的池化窗口大小为2×2，步长为2，所以本层的输出矩阵大小为16x5x5；
* **第五层：全连接的卷积层（C5）：** 输入为16x5x5；本层卷积核的尺寸为5×5，个数为120；输出矩阵大小为120x1x1；通过 reshape，转化为120维的向量。
* **第六层：全连接层（F6）：** 输入节点个数为120个，输出节点个数为84个；
* **第七层：输出层（Output）：** 本层的输入节点个数为84个，输出节点个数为10个，分别代表数字0到9。

代码如下：

```python
# 定义网络
class LeNet(nn.Module):                    # 继承父类nn.Module
    # 初始化网络
    def __init__(self):                    
        super(LeNet, self).__init__() 
        self.conv1 = nn.Conv2d(3, 16, 5)
        self.pool1 = nn.MaxPool2d(2, 2)
        self.conv2 = nn.Conv2d(16, 32, 5)
        self.pool2 = nn.MaxPool2d(2, 2)
        self.fc1 = nn.Linear(32*5*5, 120)
        self.fc2 = nn.Linear(120, 84)
        self.fc3 = nn.Linear(84, 10)
     
    # 正向传播                        # 图像尺寸参数变化
    def forward(self, x):            # input(3, 32, 32)        
        x = F.relu(self.conv1(x))    # output(16, 28, 28)
        x = self.pool1(x)            # output(16, 14, 14)
        x = F.relu(self.conv2(x))    # output(32, 10, 10)
        x = self.pool2(x)            # output(32, 5, 5)
        # x.view()：对tensor进行reshape，即重构张量的维度
        # x = x.view(x.shape[0], -1) 展平为[1个批量大小的行,32*5*5=800列]的矩阵，矩阵的每一行就是这个批量中每张图片的各个参数（即32*5*5），即矩阵中一行对应一张图片
        x = x.view(-1, 32*5*5)       # output(32*5*5) 1个批量大小的行 32*5*5=800列
        x = F.relu(self.fc1(x))      # output(120)
        x = F.relu(self.fc2(x))      # output(84)
        x = self.fc3(x)              # output(10)
        
        return x
    
# 测试验证【可选】  
# import torch
# input = torch.rand([50,3,32,32])
# model = LeNet()
# print(model)
# output = model(input)
```

LeNet-5之后，CNN沉寂了约14年。直到2012年，AlexNet在ILSVRC中一举夺魁，直接把在ImageNet数据集上的精度提升了约10个百分点，它将CNN的深度和宽度都提升到了传统算法无法企及的新高度。从此，深度学习开始在CV的各个领域“披荆斩棘”，至今深度学习仍是人工智能最热门的话题。

AlexNet作为教科书式的网络，值得每个学习深度学习的人深入研究。 AlexNet的名字取自该模型的第一作者Alex Krizhevsky。AlexNet在ImageNet中的120万张图片的1 000类分类任务上的top-1错误率是37.5%，top-5错误率则是15.3%（直接比第二名的26.2%低了约10个百分点）。

AlexNet如此成功的原因是其使网络的宽度和深度达到了前所未有的高度，而该模型也使网络的可学习参数达到了58 322 314个。为了学习这些参数，AlexNet并行使用了两块GTX 580，大幅提升了训练速度。 使用分组卷积是因为硬件资源有限，不得不将模型分到两块GPU上运行。

AlexNet网络的架构如下图所示：

<figure><img src="../.gitbook/assets/09ee9037bc724dddeec42ca40d443819.jpg" alt=""><figcaption><p>AlexNet 网络架构</p></figcaption></figure>

得益于显卡显存性能的提升，目前该网络在单块GPU上的训练已经毫无压力。除了两块GPU训练以外，该网络还有如下特点：

* \*\*ReLU 激活函数：\*\*在LeNet-5中，使用了tanh作为激活函数，在反向传播过程中，当tanh(x )中的x 的绝对值比较大的时候，该局部的梯度会非常接近于0，该现象叫作“饱和”，容易引起“**梯度消失**”现象。梯度消失是由反向传播中链式法则的乘法特性导致的，反映在深度学习的训练过程中便是越接近损失函数的参数梯度越大，从而使得这一部分参数成为主要学习的参数，而远离损失函数的参数的梯度则非常接近0，导致几乎没有梯度传到这一部分参数，从而使得这一部分参数很难学习到。为了解决这个问题，AlextNet使用了ReLU激活函数：f(x)=max(0,x)。 在ReLU中，无论x 的取值有多大，f(x)的导数都是1，也就不存在导数小于1导致的梯度消失的现象了。虽然使用ReLU的节点不会有饱和问题，但是会“死掉”，即大部分甚至所有的值为负值，从而导致该层的梯度都为0。“死神经元”是由进入网络的负值引起的（例如在大规模的梯度更新之后可能出现）。
* \*\*Dropout：\*\*在全连接层，使用了Dropout来缓解容量高的模型容易发生过拟合的现象。Dropout的使用方法是在训练过程中随机将一定比例的隐层节点置0。Dropout能够缓解过拟合的原因是每次训练都会采样一个不同的网络结构，但是这些架构是共享权值的。这种技术减轻了节点之间的耦合性，因为一个节点不能依赖网络的其他节点。因此，就能够学习到更鲁棒的特征。只有这样，节点才能适应每次采样得到的不同的网络结构。注意在测试时，是不对节点进行丢弃的。 虽然Dropout会减慢收敛速度，但其在缓解过拟合方面的优异表现仍旧使其在当前的网络中得到广泛的使用。

AlexNet 的代码这里不再介绍，网络上有很多资源，感兴趣可以参考。
