# 轻量级CNN

CNN的另外一个方向是轻量级CNN，即在不大幅度降低模型精度的前提下，尽可能地压缩模型的大小，以提高运算的速度。轻量级CNN的第一个尝试是SqueezeNet，SqueezeNet的策略是使用1×1卷积代替3×3卷积，它对标的模型是AlexNet，在本笔记中不再过多介绍。

轻量级CNN最经典的策略是深度可分离卷积，经典算法包括MobileNetV1和Xception。深度可分离卷积由深度卷积和点卷积组成，深度卷积一般是以通道为单位的3×3卷积，在卷积过程中不同通道之间没有信息交换。而信息交换则由点卷积完成，点卷积就是标准的1×1卷积。深度可分离卷积的另一个比较经典的算法是MobileNet v2，它将深度可分离卷积和残差结构进行了结合，并通过一些列理论分析和实验得出了一种更优的结合方式。

轻量级CNN的另外一种策略是选择在普通卷积和深度可分离卷积之间的一个折中方案，即分组卷积，它是在ResNeXt中提出的。所谓分组卷积，是指在深度卷积中以几个通道为一组的卷积。分组卷积的问题是组与组之间没有信息交互，这成了分组卷积的性能瓶颈。

ShuffleNet v1提出了通道洗牌策略以加强不同通道之间的信息流通，ShuffleNet v2则通过分析整个测试时间，提出了在内存访问方面更高效的卷积方式。ShuffleNet v2得出的结构是一种和DenseNet非常相似的密集连接结构。黄高团队的CondenseNet则是通过为每个分组学习一个索引层的形式来完成通道之间的信息流通。
